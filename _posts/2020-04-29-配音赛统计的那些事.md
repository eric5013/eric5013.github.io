---
layout: post
title: '配音赛统计的那些事'
date: 2020-04-29
author: 'Eric Zeng'
categories: work-as-student
header-img: “//cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/h8smBp1591765187658h8smBp.jpg"
tags:
  - 复盘
  - 学校工作
---



# 配音赛统计的那些事
好久不见，最近在忙的学生工作之一是学院的配音大赛。从**线上录播**被耍到**线上直播**再被耍到**作品打榜**，师弟们认真工作的态度令人感动。虽然付出的努力都打水漂了，但你们都是好样的。

今天来聊聊关于配音大赛的数据统计的技术实践方法。

首先了解一下配音大赛需要统计什么数据。

- 队伍信息（配音平台ID号、队伍负责人信息）
- 作品数据（上传时间、点赞量、观看量*）

第一部分好说，做个问卷发到群聊就完事，今天主要是讲一下第二个部分：统计作品数据的那些事。

## 思路分析
如果安排人来进行这个工作，分为三个步骤：

第一步，找到访问这个数据的方法（如何才能找到数据）
第二步，固定周期去访问数据（比如每日、每周），导入我们想要的数据。
第三步，将获取到的数据录入表格（Excel），或者录入到分析平台（Python，PBI，SPSS）完成后续的数据分析。
![1001](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/VDCS3O1591764931742VDCS3O.jpg)



### 寻找数据源
第一步，获取数据途径，我想到了两个方法：
第一个方法，我们打开「英语趣配音」App，打开用户的个人信息界面，作品栏就会显示他所配过的所有作品，同时在这个列表里面还有对应作品的点赞数、观看数，可以通过这个去获取到我们想要的指标。

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/eCg4Qw1591765094036eCg4Qw.jpg" alt="IMG_2130" style="zoom:25%;" />

这个方法先不评论他究竟是好还是坏，我们先讲第二种方法。第二种方法，就是通过每一个作品的分享链接，也就是我们在微信朋友圈，各队邀请他人点赞的网页。里面有当前作品的观看量和点赞量，这个是第二个方法。

<img src="https://wx2.sinaimg.cn/large/63f8f774gy1geapp1txvaj21jl2qq1l0.jpg" alt="IMG_2128" style="zoom: 25%;" />


两种方法人力都可以进行操作，当我们使用第一种方法的时候，一个页面能查阅多个作品数据，第一种的效率是高于第二种效率的（人力操作）。但倘若我们要设计一个程序的话，从读取数据的难度，第二种（读取文本）比较易于实现。

第一种（读取图片）不是不行，但需要给阿里爸爸一点经费，感兴趣的同学可以自行百度搜索**OCR**。

![Aliyun_OC](https://wx2.sinaimg.cn/large/63f8f774gy1geapoxwji8j21kw16oqcp.jpg)



鉴于学生工作大多都是**用爱发电**，经费什么的别想了。文尾再聊这个的实现方法吧。


### 手打还是复制？
其实到现在，两个方法都是可行的，如何将数据从数据源转换成Excel单元格里面的数字？也就是**导入数据**这个步骤。

![Data_Conversion](https://wx2.sinaimg.cn/large/63f8f774gy1geapoylcs0j21kw16oajb.jpg)




在这里，对比一下前面提到的两种方法。哪一种操作性更强。

第一种，通过工作人员肉眼识别的方法。（要钱的方法我不听！）将作品的点赞量和观看量手动输入到我们的电子表格中。
对于第二种，肉眼当然可以，但也可以通过复制粘贴，将数据复制到Excel里面。相对而言，复制粘贴不需要脑子记忆，误差性会更小（粘贴错单元格的，你怕不是个魔鬼）。而爬虫本质上就是一个「复制粘贴机器人」，不过它的技能比较高超，对于复杂的图文也能完美复制下来。

这样一看，是不是感觉「复制」完爆「人力」。

### 数据汇总
假设这个工作由10个人共同统计，多吗？
不多，我还觉得少了。
第一周累计241个，四周合理预测共计241 x 4 = 964个作品。到第四周每人查询约97个，查询每个作品从打开界面，找到并确认该作品（这个很耗时间）、录入作品点赞数平均需要1分钟，相当于你至少需要花一节航空气象课的时间才能完成这个统计。一个半小时一直**[点开][关闭][点开][关闭]**。
统计中途走个神在所难免，玩会儿手机，一个上午的时间就没了。

![IMG_2133](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/Y1dzDf1591765047312Y1dzDf.jpg)
如果遇到👆这样的投稿，只能通过上传时间区别
出错的概率也无形增加了

刚才笔误了，刚看到比赛规则中有这一条：

![-w375](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/ewF5yZ1591765038632ewF5yZ.jpg)

这天晚上想睡觉？

![webwxgetmsgimg](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/Ci3BAH1591765031732Ci3BAH.jpg)

我打开了VS Code，写下了一段注释，开始Coding的一天。

<img src="https://wx2.sinaimg.cn/large/63f8f774gy1geapp1ajjyj20j80603z8.jpg" alt="-w346" style="zoom:50%;" />




## 主观客观，做到一致
别被这个名字吓跑了，我不是学法的。
（法学大佬们手下留情）

罗翔老师说，如果要给~~一个人定罪~~一个事情定性，需要做到主客观相一致。刚刚讲了很多主观的因素，总的来说就是不想干那么多活但要**高效完成任务**。有轻松的法子为什么不用呢**（这里有个前提，技术满足需求）**。接下来聊两块钱客观因素。

客观而言，存在**「统计时间先后不一导致的不公平」**。举个例子你就明白了。

张三和赵四都是1000票，之后分别找了100个人在凌晨12点至凌晨1点给各自的作品点赞，我们先统计张三，但那时候水军还没开始整活；等我们统计赵四的时候；水军已经安排的明明白白。

![](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/76U6O4159176501978376U6O4.jpg)

张三肯定不乐意啊，而且这是组委会统计的问题，不是他们自己的问题。张三一怒之下买了个微博热搜控诉「比赛黑幕」。

![](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/EntdDA1591765003008EntdDA.jpg)

最后查明两个选手均使用非正规途径增加点赞量，被取消比赛资格（⚠️热搜打脸警告）

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/zbQ86i1591764990911zbQ86i.jpg" alt="-w388" style="zoom:33%;" />


上面的故事告诉一个道理：只要有人在我们统计期间给已经统计的作品点赞，那就代表我们现在所使用的数据是不准确的。（有点绕）简单点说，就是**统计时间要短、要短**。几百条数据一分钟内统计完就差不多了。

客观上人力实现不了。主客观一致，论证结束。

## 协同工作，不是为了降低效率

虽然现在疫情期间，我们大多数的时间都在家里面，但难免有的同学有安排自己的事情（**最重要的莫过于充足的睡眠**），那么在这种情况下，做到在同一个时间进行统计，就显得更加困难了。

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/mXlTsQ1591764983766mXlTsQ.jpg" style="zoom: 67%;" />

单纯为了“合作”而合作，事倍功半，百害无利。

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/oM7rFR1591764974600oM7rFR.jpg" style="zoom:33%;" />

总结一下，爬虫自动获取的优点（人工统计的缺点）
- 时间短、效率高
- 准确度99.99%（只要程序不出BUG）
- 无需协同工作，减少人力资源
- 机器不用睡觉
- 最大限度的维护统计环节公平性

我在想，策划的人有没有想过这个实际工作量，如果没有程序辅助的话。

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/rmKgtI1591764967904rmKgtI.jpg" alt="238157262" style="zoom:33%;" />

## 爬虫程序设计

我在网上找到了一些数据采集器，大多都是要收费，免费版的查询次数也十分有限。看来只能操刀子写代码了。

我是用 jQuery/Javascript 写的脚本。本来想用 `Vue` 写，因为最近 `npm` 有点问题，同时我一直是秉承着**能用手直接撕的活，就不要用牛刀**的理念，jQuery足够了。

基于Web开发的最大好处是**全平台兼容**。当我只能用手机时，也丝毫不妨碍我的日常工作。后续如果想要本地化也可以快速封装成App分发部署。（微信小程序）

程序原理100字就能说完，通过对分享网页进行分析，获取对应字段。

当输入链接的时候程序会后台会对网页数据进行采集，最后将这些数据保存到一个数组里面，然后进行下一个网页的数据采集。把每日搜索的链接保存成`arrayStr`，第二天把新增加的作品`arrayStr.push()`，再做一次遍历就完成了数据更新。这样子不就简单许多了吗？

<img src="https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/hnQPux1591764950291hnQPux.jpg" style="zoom:33%;" />

加上网页布局和样式设计，不到1000行代码。

爬虫设计的初衷是**人的重复性劳动交给机器去做，节约时间、精力，留给那些更复杂的工作上，提高生产力。**

这是批量采集时，`Debug Console` 输出效果如图：

单个作品的输出示例：
![-w670](https://cdn.jsdelivr.net/gh/eric5013/image@master/2020/06/10/eaz5p11591764947334eaz5p1.jpg)


这就是配音统计的后台实现方法。这一期阅读量不错的话，下一期谈谈配音赛的数据是如何分析的。


前文提到的方法一：

**如何通过截图导入数据？**
OCR（Optical Character Recognition）光学字符识别技术

**能干什么？** 拍图识字

（以下技术向，建议小白从这行开始自动跳过，求给作者一个“在看”鼓励一下😝）

在Windows其实有系统自带的OCR（MS Office 2007或更高版本依赖文件）主要是给OneNote用的。对于复杂文本的兼容和云计算相比还是比较弱，移动开发时也不便于调用

```
# OCR component
%programfiles%\Common Files\microsoft shared\OCR\7.0\xocr3.psp.dll `
```
随着云计算的发展，各大开发平台供应商（如阿里云、腾讯云）提供了OCR识别的API供开发者直接调用。

理想的看，每一个`UIList`子对象都是通过遍历生成，只要把布局自定义配置好，导入字段还是不难的。但实际操作上因为不同机型长宽比、DPR（Device Pixel Ratio）不同，模板很难搞，因此识别的时候准确率（准确识别数据同时正确匹配字段）比较低，之前测试的时候经常把点赞量和作品名字连起来。时间比较赶，来不及调教（深度学习）云计算就放弃了。而且列表里面的数据也少了，200多个作品存成xml才83KB，一张屏幕截图估计就得2MB，对于这个项目需求，OCR算是完败了。

不过，OCR的应用场景还是很多的，比如实景翻译、文献检索、扫描试卷、拍照摘录等等。感兴趣的可以看一下阿里的OCR产品，实名认证后有500次免费的额度，尝鲜足够了。

**版权声明：CC-BY-NC-SA 4.0**